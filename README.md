# üèóÔ∏è An√°lise de Pipeline de Obras P√∫blicas (ObrasGov - DF)

<p align="center">
  <a href="#üìò-vis√£o-geral">Vis√£o Geral</a> ‚Ä¢
  <a href="#üìä-1-principais-insights-visuais">Principais Insights</a> ‚Ä¢
  <a href="#‚öôÔ∏è-2-instala√ß√£o-e-execu√ß√£o">Instala√ß√£o e Execu√ß√£o</a> ‚Ä¢
  <a href="#üìÇ-3-estrutura-de-pastas">Estrutura de Pastas</a> ‚Ä¢
  <a href="#üîç-4-o-pipeline-de-dados--an√°lise-dos-notebooks">Pipeline de Dados</a> ‚Ä¢
  <a href="#üìù-conclus√£o">Conclus√£o</a> 
</p>

## üìò Vis√£o Geral

Este projeto √© uma **an√°lise de ponta a ponta (end-to-end)** do pipeline de dados de obras de infraestrutura no **Distrito Federal**, utilizando dados da **API p√∫blica ObrasGov**.

O objetivo √© construir um **pipeline ETL completo**, desde a extra√ß√£o de dados brutos at√© um banco de dados relacional e, finalmente, a gera√ß√£o de um **dashboard de insights acion√°veis**.

---

## üìä 1. Principais Insights Visuais

Nesses exmplos (mais nos notebooks) de visualiza√ß√µes foi revelado **padr√µes claros** sobre o portf√≥lio de projetos no DF:

| Visualiza√ß√£o | Insight Chave |
|:-------------:|:--------------|
| <img src="./assets/investimento_viz.png" width="450"/> | **Investimento por Projeto:** Este gr√°fico de eixo duplo exp√µe uma **desconex√£o** crucial entre o **volume de investimento** (barras) e a **quantidade de projetos** (linha).  |
| <img src="./assets/gargalo_viz.png" width="450"/> | **Gargalo de Planejamento:** 76,1% do portf√≥lio (520 projetos) est√° estagnado na fase de *Planejamento*, provando que o desafio n√£o √© falha, mas **in√©rcia em iniciar os projetos**. |
| <img src="./assets/dnit_viz.png" width="450"/> | **Concentra√ß√£o de Capital:** O *Eixo Econ√¥mico* (Rodovias) domina o investimento, respondendo sozinho por **64,9% (R$ 2,0 Bilh√£o)** de todo o valor. |
| <img src="./assets/eficiencia_viz.png" width="450"/> | **Efici√™ncia Social:** O maior retorno social (*empregos por milh√£o*) n√£o est√° nos megaprojetos, mas em **obras sociais**, como *Constru√ß√£o de Unidade B√°sica de Sa√∫de* (140+ empregos/milh√£o). |

---

## ‚öôÔ∏è 2. Instala√ß√£o e Execu√ß√£o

### Pr√©-requisitos
- Python **3.10+**  
- Docker Desktop
- Git  

---

### Instala√ß√£o

#### üîπ Clone o Reposit√≥rio
```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```
#### üîπ Crie o Ambiente Virtual e Instale as Depend√™ncias
```bash
# Crie o ambiente virtual
python -m venv venv

# Ative o ambiente (Linux/Mac)
source venv/bin/activate
# (No Windows)
venv\Scripts\activate

# Instale as bibliotecas
pip install -r requirements.txt
```
#### üîπ Configure as Vari√°veis de Ambiente
Crie um arquivo chamado .env na raiz do projeto com suas credenciais:

```bash
PG_HOST=localhost
PG_PORT=5432
PG_DB=meu_banco
PG_USER=meu_usuario
PG_PASSWORD=minha_senha_secreta
```
> ‚ö†Ô∏è Este arquivo √© ignorado pelo Git (.gitignore).

#### üîπ Inicie o Banco de Dados (via Docker)
```bash
docker run --name meu-postgres \
  -e POSTGRES_PASSWORD=minha_senha_secreta \
  -e POSTGRES_USER=meu_usuario \
  -e POSTGRES_DB=meu_banco \
  -p 5432:5432 \
  -d postgres
```
### Execu√ß√£o

#### üîπ Execute o Pipeline de Notebooks
√â essencial executar os notebooks na **ordem correta**, pois eles dependem entre si.

```text
notebooks/
‚îú‚îÄ‚îÄ 01_data_extraction.ipynb
‚îú‚îÄ‚îÄ 02_data_transformation.ipynb
‚îú‚îÄ‚îÄ 03_data_load.ipynb
‚îî‚îÄ‚îÄ 04_data_analysis.ipynb
```
## üìÇ 3. Estrutura de Pastas
```text
.
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_extraction.ipynb     # (E) Extra√ß√£o de dados brutos da API
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_transformation.ipynb # (T) Limpeza, Normaliza√ß√£o e Feature Engineering
‚îÇ   ‚îú‚îÄ‚îÄ 03_data_load.ipynb           # (L) Carga dos dados limpos no PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ 04_data_analysis.ipynb       # (An√°lise) Visualiza√ß√£o e gera√ß√£o de insights
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # (Sa√≠da do Notebook 01)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dados_brutos.parquet
‚îÇ   ‚îî‚îÄ‚îÄ processed/                   # (Sa√≠da do Notebook 02)
‚îÇ       ‚îî‚îÄ‚îÄ dados_projetos_limpos.parquet
‚îÇ
‚îú‚îÄ‚îÄ .env                             # (Configura√ß√£o local - N√ÉO ENVIAR AO GIT)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üîç 4. O Pipeline de Dados ‚Äî An√°lise dos Notebooks
### 01_data_extraction.ipynb (Extra√ß√£o)
- **Fun√ß√£o**: Conecta-se √† API p√∫blica do ObrasGov, filtrando projetos pelo estado DF.

- **Processo**: API com limita√ß√µes de extra√ß√£o e pagina√ß√£o de dados.

- **Sa√≠da**: dados_brutos.parquet salvo em data/raw/.

### 02_data_transformation.ipynb (Transforma√ß√£o)
- **Fun√ß√£o**: O ‚ÄúT‚Äù do ETL ‚Äî limpeza, normaliza√ß√£o e enriquecimento.

- **Processos Principais**:

  - Remo√ß√£o de duplicados com drop_duplicates(subset='id_unico').

  - Padroniza√ß√£o de texto (.str.strip().str.upper()).

  - Cria√ß√£o de novas features ex.:

    -  valor_total_investimento

    -  empregos_por_milhao_brl

    - status_agrupado

    - faixa_valor

- **Sa√≠da**: DataFrames limpos e enriquecidos em data/processed/.

### 03_data_load.ipynb (Carga)
- **Fun√ß√£o**: O ‚ÄúL‚Äù do ETL ‚Äî> popula o banco de dados.

- **Processos**: Armazenamento de dados .paquet em .db

- **Sa√≠da**: Banco PostgreSQL relacional em container.

### 04_data_analysis.ipynb (An√°lise)
- **Fun√ß√£o**: Conecta-se ao banco e gera as visualiza√ß√µes principais.

- **Processo**: Transforma√ß√£o de dados em **Insight**.

- **Resultado**: Gera√ß√£o dos gr√°ficos que originaram os insights do in√≠cio deste README.

## üìù Conclus√£o
Este pipeline demonstra a import√¢ncia de um fluxo de dados limpo, integrado e audit√°vel, permitindo revelar gargalos estruturais e inefici√™ncias financeiras em obras p√∫blicas do DF.

> Resultado final: uma base de dados confi√°vel, visualiza√ß√µes significativas e uma vis√£o clara sobre onde, e por que, o progresso para.

**Autor**: [Tiago Bittencourt](https://github.com/TiagoSBittencourt)  
**Fonte de dados**: [API ObrasGov.br](https://api.obrasgov.gestao.gov.br/obrasgov/api/swagger-ui/index.html)